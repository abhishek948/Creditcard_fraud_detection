{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Detection using Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Librarise\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x1243941b6a0>,\n",
       "  <matplotlib.patches.Wedge at 0x1243941bd90>],\n",
       " [Text(-1.199982328767447, 0.006512345649200875, 'Genuine '),\n",
       "  Text(1.1999823292557037, -0.006512255681064681, 'Fraud ')],\n",
       " [Text(-2.4999631849321813, 0.013567386769168488, '99.827%'),\n",
       "  Text(2.4999631859493827, -0.01356719933555142, '0.173%')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Genuine ','Fraud ']\n",
    "plt.pie(dataset['Class'].value_counts(), labels=labels, autopct='%0.3f%%' , pctdistance=2.5, labeldistance=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Class'].value_counts()\n",
    "# Class 0 is Legitimate , Genuine Transactions\n",
    "# Class 1 represents Fraudulent Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283721</th>\n",
       "      <td>284802</td>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283722</th>\n",
       "      <td>284803</td>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283723</th>\n",
       "      <td>284804</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283724</th>\n",
       "      <td>284805</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283725</th>\n",
       "      <td>284806</td>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283726 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index      Time         V1         V2        V3        V4        V5  \\\n",
       "0            0       0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            1       0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            2       1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            3       1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            4       2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...        ...       ...        ...        ...       ...       ...       ...   \n",
       "283721  284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "283722  284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "283723  284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "283724  284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "283725  284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8  ...       V21       V22       V23  \\\n",
       "0       0.462388  0.239599  0.098698  ... -0.018307  0.277838 -0.110474   \n",
       "1      -0.082361 -0.078803  0.085102  ... -0.225775 -0.638672  0.101288   \n",
       "2       1.800499  0.791461  0.247676  ...  0.247998  0.771679  0.909412   \n",
       "3       1.247203  0.237609  0.377436  ... -0.108300  0.005274 -0.190321   \n",
       "4       0.095921  0.592941 -0.270533  ... -0.009431  0.798278 -0.137458   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "283721 -2.606837 -4.918215  7.305334  ...  0.213454  0.111864  1.014480   \n",
       "283722  1.058415  0.024330  0.294869  ...  0.214205  0.924384  0.012463   \n",
       "283723  3.031260 -0.296827  0.708417  ...  0.232045  0.578229 -0.037501   \n",
       "283724  0.623708 -0.686180  0.679145  ...  0.265245  0.800049 -0.163298   \n",
       "283725 -0.649617  1.577006 -0.414650  ...  0.261057  0.643078  0.376777   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "283721 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77      0  \n",
       "283722 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79      0  \n",
       "283723  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88      0  \n",
       "283724  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00      0  \n",
       "283725  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00      0  \n",
       "\n",
       "[283726 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283726, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle Amount Columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss =StandardScaler()\n",
    "X['Amount'] = ss.fit_transform(X['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuer Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model=ExtraTreesClassifier()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01238707 0.01779924 0.03258339 0.03847677 0.01349677 0.01464732\n",
      " 0.02212112 0.01470558 0.03394537 0.07106236 0.06912909 0.10347872\n",
      " 0.01338688 0.12476409 0.01294325 0.06076539 0.15082049 0.045292\n",
      " 0.01716162 0.01360956 0.01707166 0.01312476 0.00968472 0.01292525\n",
      " 0.01070184 0.01539879 0.01403025 0.01183941 0.01264725]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranked_features=pd.Series(model.feature_importances_,index=X.columns)\n",
    "ranked_features.nlargest(15).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[['V17','V14','V12','V10','V11','V16','V18','V4','V9','V7','V3','V21','V19','V8','V2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handled Imblanced Dataset - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from collections import Counter\n",
    "# print('Original dataset shape %s' % Counter(y))\n",
    "# smote = SMOTE(random_state=10)\n",
    "# X_smote,y_smote = smote.fit_resample(X,y)\n",
    "# print('Resampled dataset shape %s' % Counter(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets create train and test data\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Dense(units=20, kernel_initializer='he_uniform', activation='relu',input_dim=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Dense(units=10, kernel_initializer='he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Dense(units=5, kernel_initializer='he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15208/15208 [==============================] - 26s 2ms/step - loss: 0.0713 - accuracy: 0.9639 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 2/10\n",
      "15208/15208 [==============================] - 23s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "15208/15208 [==============================] - 24s 2ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
      "Epoch 4/10\n",
      "15208/15208 [==============================] - 24s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "15208/15208 [==============================] - 29s 2ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "15208/15208 [==============================] - 26s 2ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "15208/15208 [==============================] - 25s 2ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "15208/15208 [==============================] - 25s 2ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
      "Epoch 9/10\n",
      "15208/15208 [==============================] - 25s 2ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "15208/15208 [==============================] - 25s 2ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1243e153100>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.fit(X_train,y_train, batch_size=10, validation_split=0.33, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model With Kernel Tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "1. How many number of hidden layers we should have?\n",
    "2. How many number of neurons we should have in hidden layers?\n",
    "3. Learning Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project project\\creditcarddetection\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='project',\n",
    "    project_name='creditcarddetection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import tensorflow as tf\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 09m 12s]\n",
      "val_accuracy: 0.998742938041687\n",
      "\n",
      "Best val_accuracy So Far: 0.998742938041687\n",
      "Total elapsed time: 00h 09m 12s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "num_layers        |16                |10                \n",
      "units_0           |448               |384               \n",
      "units_1           |320               |64                \n",
      "learning_rate     |0.01              |0.01              \n",
      "units_2           |448               |32                \n",
      "units_3           |224               |32                \n",
      "units_4           |160               |32                \n",
      "units_5           |128               |32                \n",
      "units_6           |480               |32                \n",
      "units_7           |192               |32                \n",
      "units_8           |256               |32                \n",
      "units_9           |192               |32                \n",
      "\n",
      "Epoch 1/10\n",
      "7094/7094 [==============================] - 80s 11ms/step - loss: 46070.7594 - accuracy: 0.9945 - val_loss: 0.0117 - val_accuracy: 0.9985\n",
      "Epoch 2/10\n",
      "7094/7094 [==============================] - 81s 11ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.0122 - val_accuracy: 0.9985\n",
      "Epoch 3/10\n",
      "7094/7094 [==============================] - 73s 10ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.0123 - val_accuracy: 0.9985\n",
      "Epoch 4/10\n",
      "7093/7094 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9983"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-81cc7556dc23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mClearTrainingOutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Get the optimal hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbest_hps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'callbacks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\kerastuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m    140\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1131\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs = 10, validation_data = (X_test, y_test), callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the model with the optimal hyperparameters and train it on the data\n",
    "# model = tuner.hypermodel.build(best_hps)\n",
    "# model.fit(X_train, y_train, epochs = 1, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
